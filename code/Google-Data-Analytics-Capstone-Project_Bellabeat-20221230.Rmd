---
title: 'Google Data Analytics Professional Certificate: Bellabeat - How can a Wellness Technology Company Play it Smart'
author: 'Alexander Karl Rivera'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    toc: true
---

# Introduction

This project serves as the capstone project for the Google Data Analytics Professional Certificate.

[**Bellabeat**](https://bellabeat.com/) is a successful small company which is high-tech manufacturer of health-focused products for women, furthermore they have a potential to become a major player in the global smart device market.

## Stakeholders: 
- Urška Sršen: Bellabeat’s cofounder and Chief Creative Officer

- Sando Mur: Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team

- Bellabeat marketing analytics team: A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat’s marketing strategy.

## Products:

- Bellabeat app: The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products.

- Leaf: Bellabeat’s classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects to the Bellabeat app to track activity, sleep, and stress.

- Time: This wellness watch combines the timeless look of a classic timepiece with smart technology to track user activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your daily wellness.

- Spring: This is a water bottle that tracks daily water intake using smart technology to ensure that you are appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your hydration levels.

- Bellabeat membership: Bellabeat also offers a subscription-based membership program for users. Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals.


# Business Task
Sršen has tasked us to analyzed smart device usage data in order to gain insight into how consumers use non-Bellabeat smart devices and apply these insights to one of the Bellabeat products.

- Check the different smart device usage trends

- Examine the applicability of these trends to Bellabeat customers
  
- Explore on how these trends can help influence Bellabeat marketing strategy


# Prepare; Data Source, Type, Credibility ,Privacy Ethics and Limitations

## Data Source and Type

The original datasets can be referenced under [zenodo.org](https://zenodo.org/record/53894). There are two datasets which covers the period from March to May 12, 2016. Each datasets have a data timeframe of one month and are saved into csv types.

For the purpose of this study, I have utlized the dataset based on [Kaggle](https://www.kaggle.com/datasets/arashnic/fitbit) provided by user ["Möbius"](https://www.kaggle.com/arashnic). This dataset includes the fitness tracker data from thirty Fitbit users on the duration of April 12 to May 12, 2016.  Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.  

## Data Licensing

The Dataset has been licensed as [CC0: Public Domain information](https://creativecommons.org/publicdomain/zero/1.0/).

## Data Privacy

The dataset has omitted any private information of the respondents. 

## Data Credibility

- Reliable: Yes - Low

The dataset includes the generally accepted sample size of 30 respondents. 

- Original: Yes - High

The data was generated by Fitbit users who responded to the survey conducted by Amazon Mechanical Turk. [Amazon Mechanical Turk (MTurk)](https://www.mturk.com/) is a crowdsourcing marketplace that makes it easier for individuals and businesses to outsource their processes and jobs to a distributed workforce who can perform these tasks virtually. MTurk is a secondary-party data provider.

- Comprehensive: Yes - Medium

The dataset includes the physical activity, heart-rate, sleep monitoring and weight in three timeframes: daily, hourly and minute. However the dataset do not provide any demographic information, which could have been necessary information for this analysis.

- Current: No - Low

The dataset is based on a 2016 survey. There have been no update on the data with sufficient sample size since then.

- Cited: Yes - High

The dataset referenced under [zenodo.org](https://zenodo.org/record/53894) have cited the [authors, publication date, Digital Object Identifier and Licensing](Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016). Crowd-sourced Fitbit datasets 03.12.2016-05.12.2016 [Data set]. Zenodo. https://doi.org/10.5281/zenodo.53894).


Based on the assessment above, the data can be considerate as moderately credible. 

## Data Limitations

- The dataset is based on a 2016 survey and may not represent current customer trend. We can disregard this limitation for this case study.
- The data does not include any information on the Fitbit users demography. This information will enable that analysis will only focus on female, who are the target customer. I will be assuming that all of the data points are from female participants.
- The dataset only covers a one month timeframe - the timeframe is too short to cover for long term habits and benefits of using the Fitbit app.

# Process - Data Cleaning

I will be utilizing the Kaggle Notebook R for this analysis. This tool provide ease of data exploration, cleaning, mutation, transformation, visualization and reporting of the analysis. Furthermore, it provide simpler referencing of the analysis and source file. 

## Loading the necessary packages

```{r library, include = TRUE}
library(tidyverse)
library(lubridate)
library(readr)
library(here)
library(janitor)
library(ggplot2)
```

## Datasets

There are 18 csv files included in the dataset but for the purpose of this study, I will utilized six files. One summary file and five daily tracker will be used for the analysis. These data are listed below.

```{r data, include = TRUE}
DailyActivity <- read.csv("../data/FitBit-Fitness-Tracker-Data/dailyActivity_merged.csv")
DailyCalories <- read.csv("../data/FitBit-Fitness-Tracker-Data/dailyCalories_merged.csv")
DailyIntensities <- read.csv("../data/FitBit-Fitness-Tracker-Data/dailyIntensities_merged.csv")
DailySteps <- read.csv("../data/FitBit-Fitness-Tracker-Data/dailySteps_merged.csv")
DailySleep <- read.csv("../data/FitBit-Fitness-Tracker-Data/sleepDay_merged.csv")
weightLogInfo <- read.csv("../data/FitBit-Fitness-Tracker-Data/weightLogInfo_merged.csv")
```

DailyActivity - summary of daily activity data. It summarizes the data from DailyCalories, DailyIntensities and DailySteps data.
DailyCalories - Daily calories tracker data
DailyIntensities - Daily activity intensity level tracker data
DailySteps - Daily steps tracker data
DailySleep - Daily sleep tracker data
weightLogInfo - weight log tracker data

The data are imported into different dataframes.

**Explore the dataframe**

```{r include=TRUE}
head(DailyActivity) #For reporting, I will only be showing the main summary
#head(DailyCalories)
#head(DailyIntensities)
#head(DailySteps)
#head(DailySleep)
#head(weightLogInfo)
```

Based on the unique number check, two dataframes have participants who did not submitted their data - these dataframes are for the DailySleep ( `r 33 - n_distinct(DailySleep$Id)` did not submit) and WeightLog ( `r 33 - n_distinct(weightLogInfo$Id)` did not submit)

## Data Cleaning and Transformation

This process will check for any null observations, duplicates and other inconsistencies in the databases. 

**Column name Formatting**

I will be utilizing the "snake_case" for the consistency of the column names case formatting.

```{r include = TRUE}
column_formatting <- "snake"

# Using the clean_names under the janitor package

DailyActivity <- clean_names(DailyActivity, "snake")
DailyCalories<- clean_names(DailyCalories, "snake")
DailyIntensities <- clean_names(DailyIntensities, "snake")
DailySteps <- clean_names(DailySteps, "snake")
DailySleep <- clean_names(DailySleep, "snake")
weightLogInfo <- clean_names(weightLogInfo, "snake")
```

```{r include = TRUE} 
#Checking if dataframe columns have been updated
head(DailyActivity) #For reporting, I will only be showing the main summary
#head(DailyCalories)
#head(DailyIntensities)
#head(DailySteps)
#head(DailySleep)
#head(weightLogInfo)
```

**Date and Time Formatting**

Based on the head function above, the dates are in "character" type - these data should be in date, time or datetime format. I will be adding a new column for the time and for the day of the week data. 

```{r DateTimeFormatting, include = TRUE}

DailyActivity <- DailyActivity %>% 
  mutate(activity_date = mdy(activity_date), day_of_week = wday(activity_date, label = TRUE), total_minutes = very_active_minutes +  fairly_active_minutes + lightly_active_minutes + sedentary_minutes)

DailyCalories <- DailyCalories %>% 
  rename(activity_date = activity_day) %>% 
  mutate(activity_date = mdy(activity_date), day_of_week = wday(activity_date, label = TRUE))

DailyIntensities <- DailyIntensities %>% 
  rename(activity_date = activity_day) %>%
  mutate(activity_date = mdy(activity_date), day_of_week = wday(activity_date, label = TRUE), total_minutes = very_active_minutes +  fairly_active_minutes + lightly_active_minutes + sedentary_minutes)

DailySteps <- DailySteps %>% 
  rename(activity_date = activity_day) %>% 
  mutate(activity_date = mdy(activity_date), day_of_week = wday(activity_date, label = TRUE))

DailySleep <- DailySleep %>% 
  rename(activity_date = sleep_day) %>% 
  mutate(activity_date = date(mdy_hms(activity_date)), day_of_week = wday(activity_date, label = TRUE))

weightLogInfo <- weightLogInfo %>% 
  rename(activity_date = date) %>% 
  mutate(activity_date = date(mdy_hms(activity_date)), day_of_week = wday(activity_date, label = TRUE))
```

**Intensity Time Consistency**

There is a provided time for the intensity (in minutes) for the DailyActivity and DailyIntensities datasets, to verify that there are no issues in the datasets, I will check if total_minutes is less than or equal to 1,440 minutes (24 hour-period). A return value of zero means that there all value are within the 24-hour period. 

```{r IntensityTimeConsistency, include=TRUE}
#Check for inconsistencies on the Summary
sum(filter(DailyActivity, total_minutes > 1440))

#Check for inconsistencies on the Individual Log
sum(filter(DailyIntensities, total_minutes > 1440))
```
**Data Consistency**

I cross-checked the values provided in the individual tracker to the summary data. If there is a difference between the the individual data tracker and the summary, I will utilize the provided observation on the individual tracker. A return value of zero means that there is no issue with the dataset.

```{r DataConsistency, include = TRUE}
#Check for possible inconsintencies between the DailyActivity and DailyCalories
merge(DailyActivity, DailyCalories, by = c("id", "activity_date")) %>% 
  filter(calories.x != calories.y) %>% 
  sum()

#Check for possible inconsintencies between the DailyActivity and DailyIntensities
merge(DailyActivity, DailyIntensities, by = c("id", "activity_date")) %>% 
  filter(total_minutes.x != total_minutes.y) %>%
  sum()

#Check for possible inconsintencies between the DailyActivity and DailySteps
merge(DailyActivity, DailySteps, by = c("id", "activity_date")) %>% 
  filter(total_steps != step_total) %>%
  sum()
```

**Check for duplicate data**

```{r CheckDuplicate, include = TRUE}

# The duplicated function will check for duplicate rows and return it as TRUE. In consideration, Boolean True has a value of 1 and Boolean FALSE has a value of 0, so if we summed up the dataframes that have no duplicates it will return to zero

tibble("DailyActivity" = sum(duplicated(DailyActivity)),
       DailyCalories = sum(duplicated(DailyCalories)),
       DailyIntensities = sum(duplicated(DailyIntensities)),
       DailySteps = sum(duplicated(DailySteps)),
       DailySleep = sum(duplicated(DailySleep)),
       weightLogInfo = sum(duplicated(weightLogInfo)))
```

Based on the nested function above, the DailySleep have `r sum(duplicated(DailySleep))` duplicate rows. I will now removed all the duplicate rows.

```{r DailySleepDuplicate, include=TRUE}
#There are 413 observations in the initial dataset including the 3 duplicates
DailySleep <- distinct(DailySleep)

#Check if the duplicate rows have been removed. It should return 410.
tibble(distinct_sleep_observation = nrow(DailySleep))
```

**Check for missing values**

```{r CheckMissingValue, include = TRUE}

# The is.na function will check for blank data and return it as TRUE. In consideration, Boolean True has a value of 1 and Boolean FALSE has a value of 0, so if we summed up the dataframes that have blank data it will return to zero

sum(is.na(DailyActivity))
sum(is.na(DailyCalories))
sum(is.na(DailyIntensities))
sum(is.na(DailySteps))
sum(is.na(DailySleep))
sum(is.na(weightLogInfo))
```

I will now verify where is the missing value in the WeightLogInfo datasets by creating a summary and checking what row have the NULL values and verify if it will have an impact on my analysis.

```{r VerifyMissingValue, include = TRUE}
# Checking for the number of the unique ID

summary(weightLogInfo)
```
All of the missing values are located under the "Fat" column. I choose to omit this column as it will not have an impact on my analysis and to have consistency on the dataframes with values.

```{r WeightLog, include=FALSE}

weightLogInfo <- weightLogInfo[,-5]
```

**Merge Datasets**

To simplify the analysis process for correlations, I will be merging the different information into one summary dataframe. I will be adding the weightLogInfo and DailySleep into the DailyActivity dataframe.

```{r MergeDataframes, include=TRUE}
DailySummary <- DailyActivity %>% 
  full_join(DailySleep[-6], by = c("activity_date","id")) %>% 
  full_join(weightLogInfo[-8], by = c("activity_date","id"))

str(DailySummary)
```

# Analyze

The data has now been cleaned for analysis. This section will focus on gaining insights from the datasets.

## Summary Data
The **DailySummary** covers a time period of `r n_distinct(DailySummary$activity_date)` days from `r min(DailySummary$activity_date)` to `r max(DailySummary$activity_date)`. 

```{r DatasetsSummary, include=TRUE}
# Summary on the Datasets
DailySummary %>% 
  select(total_steps, total_distance,sedentary_minutes,total_minutes,calories,total_minutes_asleep,weight_kg, bmi) %>% 
  summary()
```

```{r}
# Summary of number observations for the different datasets

as.data.frame(tibble("DailyActivity" = nrow(DailyActivity),
      "DailyCalories" = nrow(DailyCalories),
      "DailyIntensities" = nrow(DailyIntensities),
      "DailySteps" = nrow(DailySteps),
      "DailySleep" = nrow(DailySleep),
      "weightLogInfo" = nrow(weightLogInfo)))  %>% 
          pivot_longer(cols = c("DailyActivity","DailyCalories", "DailyIntensities", "DailySteps", "DailySleep", "weightLogInfo"), names_to = "feature", values_to = "observation")

```
```{r ParticipantSummary}
# Summary of participants for each activity

ParticipantSummary <- as.data.frame(tibble("DailyActivity" = n_distinct(DailyActivity$id),
                             "DailyCalories" = n_distinct(DailyCalories$id), 
                             "DailyIntensities" = n_distinct(DailyIntensities$id), 
                             "DailySteps" = n_distinct(DailySteps$id), 
                             "DailySleep" = n_distinct(DailySleep$id), 
                             "weightLogInfo" = n_distinct(weightLogInfo$id)))

ParticipantSummary <- ParticipantSummary %>% 
  pivot_longer(cols = c("DailyActivity","DailyCalories", "DailyIntensities", "DailySteps", "DailySleep", "weightLogInfo"), names_to = "feature", values_to = "participant")

ParticipantSummary

```

Upon examination of the provided summary statistics above, I noticed that the minimum value for some of the tracked activities is zero (0) such as total_steps (`r count(filter(DailySteps,step_total == 0))`), total_distance (`r count(filter(DailyIntensities,(sedentary_active_distance + light_active_distance + moderately_active_distance + very_active_distance) == 0))`), sedentary_minutes (`r count(filter(DailyIntensities,sedentary_minutes == 0))`) and calories (`r count(filter(DailyCalories,calories == 0))`). With the consideration that zero data are unfeasible, I have omitted the data in the individual datasets. For the **DailySummary**, these zero-value will be retained but will be filtered out during analysis and visualizations.

```{r, include=TRUE}
# Remove Zero Value Data from the Individual Datasets
CleanedDailySteps <- DailySteps %>% 
  filter(step_total != 0)

CleanedDailyCalories <- DailyCalories %>% 
  filter(calories != 0)

CleanedDailyIntensities <- DailyIntensities %>% 
  filter(sedentary_minutes != 0) 
```

## Explore Datasets

**Explore Daily Steps**

According to World Health Organization, for general fitness, most adults should aim for 10,000 steps per day. This figure may rise or fall depending on a person's age, current fitness level, and health goals. This recommendation comes from the Centers for Disease Control and Prevention (CDC).

```{r}

CleanedDailySteps %>% 
  group_by(day_of_week) %>% 
  summarise(mean_total_steps = round(mean(step_total),2))  #create a summary of the mean total steps group by day_of_week
```

**Explore Daily Calories**

```{r}
CleanedDailyCalories %>% 
  group_by(day_of_week) %>% 
  summarise(mean_calories = mean(calories))
```

**Explore Daily Intensities**

```{r}

# Average number of steps per by day of week
IntensityType <- tibble('avg_sedentary_minutes' = round(mean(CleanedDailyIntensities$sedentary_minutes), digits = 2),
       'avg_lightly_active_minutes' = round(mean(CleanedDailyIntensities$lightly_active_minutes), digits = 2),
       'avg_fairly_active_minutes' = round(mean(CleanedDailyIntensities$fairly_active_minutes), digits = 2),
       'avg_very_active_minutes' = round(mean(CleanedDailyIntensities$very_active_minutes), digits = 2))

IntensityType <- IntensityType %>% 
  pivot_longer(cols = c("avg_sedentary_minutes","avg_lightly_active_minutes", "avg_fairly_active_minutes", "avg_very_active_minutes", ), names_to = "intensity_type", values_to = "mean_time")

IntensityType <- IntensityType %>% 
  mutate(percentage = round(mean_time/sum(mean_time)*100,2))

IntensityType
```

**Explore Daily Sleep**

According from CDC, adults between 18 and 64 years old need seven to eight hours of good-quality sleep per night. 

```{r}
# Convert the time in minutes to hours - sleep time and time in bed
CleanedDailySleep <- DailySleep %>% 
  mutate(total_hours_asleep = total_minutes_asleep/60, 
         total_hours_in_bed = total_time_in_bed/60)

CleanedDailySleep %>% 
  group_by(day_of_week) %>% 
  summarise(mean_hours_asleep = mean(total_hours_asleep))
```

# Share

This section will visualize the analyze conducted in the previous section.
**Daily Steps**

```{r}
# Average number of steps per by day of week
average_daily_steps <- round(mean(CleanedDailySteps$step_total), digits = 2)

CleanedDailySteps %>% 
  group_by(day_of_week) %>% 
  summarise(mean_total_steps = round(mean(step_total),2)) %>%
  ggplot() +
    geom_col(mapping = aes(x = day_of_week, mean_total_steps), color = 2, fill = 2) + 
    geom_hline(yintercept = average_daily_steps, linetype = 'dashed', color = 9) +
    geom_text(aes(y =average_daily_steps, label = average_daily_steps), x = 5, size = 3, vjust = -0.30)
```

**Daily Calories**

```{r}
# Average calories burned per by day of week
average_daily_calories <- round(mean(CleanedDailyCalories$calories), digits = 2)

CleanedDailyCalories %>% 
  group_by(day_of_week) %>% 
  summarise(mean_calories = mean(calories)) %>%  #create a summary of the mean calories burned group by day_of_week
  ggplot() +
    geom_col(mapping = aes(x = day_of_week, mean_calories), color = 2, fill = 2) + 
    labs(x="Day of the Week", y="Calories Burned") + 
    geom_hline(yintercept = average_daily_calories, linetype = 'dashed', color = 10) +
    geom_text(aes(y =average_daily_calories, label = average_daily_calories), x = 5, size = 3, vjust = -0.30)
```

**Daily Intensities**

```{r}
## Create a pie chart to check for the distributions of Intensity minutes.

# Average number of steps per by day of week
IntensityType <- tibble('avg_sedentary_minutes' = round(mean(CleanedDailyIntensities$sedentary_minutes), digits = 2),
       'avg_lightly_active_minutes' = round(mean(CleanedDailyIntensities$lightly_active_minutes), digits = 2),
       'avg_fairly_active_minutes' = round(mean(CleanedDailyIntensities$fairly_active_minutes), digits = 2),
       'avg_very_active_minutes' = round(mean(CleanedDailyIntensities$very_active_minutes), digits = 2))

IntensityType <- IntensityType %>% 
  pivot_longer(cols = c("avg_sedentary_minutes","avg_lightly_active_minutes", "avg_fairly_active_minutes", "avg_very_active_minutes", ), names_to = "intensity_type", values_to = "mean_time")

IntensityType <- IntensityType %>% 
  mutate(percentage = round(mean_time/sum(mean_time)*100,2)) %>% 
  ggplot(aes(x = "", y = percentage, fill = intensity_type)) + 
  geom_bar( stat = "identity", width =1, show.legend = TRUE, color = 1) +
  coord_polar(theta = "y") + 
  geom_text(aes(label = ifelse(percentage <2,"", paste(round(percentage,digits = 2),"%",sep="")))
            ,position=position_stack(vjust = 0.5)
            , color = 1)

IntensityType 
```

**Daily Sleep**

```{r}
# Convert the time in minutes to hours - sleep time and time in bed
CleanedDailySleep <- DailySleep %>% 
  mutate(total_hours_asleep = total_minutes_asleep/60, 
         total_hours_in_bed = total_time_in_bed/60)

  
# Average time by day of week
average_sleep_hours <- round(mean(CleanedDailySleep$total_hours_asleep), digits = 2)
average_in_bed_hours <- round(mean(CleanedDailySleep$total_hours_in_bed), digits = 2)

CleanedDailySleep %>% 
  group_by(day_of_week) %>% 
  summarise(mean_hours_asleep = mean(total_hours_asleep)) %>%
  ggplot() +
    geom_col(mapping = aes(x = day_of_week, mean_hours_asleep), color = 2, fill = 2) + 
    geom_hline(yintercept = average_sleep_hours, linetype = 'dashed', color = 10) +
    geom_hline(yintercept = average_in_bed_hours, linetype = 'dashed', color = 1) +
    geom_text(aes(y =average_sleep_hours, label = average_sleep_hours), x = 5, size = 3, vjust = -0.30) + 
    geom_text(aes(y =average_in_bed_hours, label = average_in_bed_hours), x = 5, size = 3, vjust = -0.30)
```

Participants average a 6.99 hours sleeping which is just below the recommended a minimum of 7 hours of good-night sleep. Participants averaged a 39 minutes of staying in the bed after waking up.

**Daily Logging**

```{r}
#Check for the number of logged activities
DailyActivity %>% 
  group_by(day_of_week) %>% 
  ggplot(mapping = aes(x = day_of_week, stat="count"), fill = 2) +
  geom_bar() + 
  labs(x="Day of the Week", y="Logging Frequency")
```

Most of the participants prefer or remember to log their activities on the app during midweek between Tuesday to Thursday.


# Conclusion

I will be providing my insights and providing my recommendations based on the analysis above.

- Majority of tracked data (81.33%) using Fitbit app were sedentary activities. It means that the users have little to no exercise.
- There is minimal participation and observation on the weight (67).
- There is around `r round(nrow(DailySleep)/nrow(DailySummary),2)*100`% participation on the sleep tracking. Some of the possible cause for this are participants charged their devices or removed their Fitbit devices during sleeping time.

# Recommendation

This section will provide recommendation on the Bellabeat products based on the analyze smart device usage trend. 

With the sedentary activities, I recommend the following for the  Bellabeat app or membership:

- A reminder when a sedentary time period has been reached

- As there is less activity during the weekend, Bellabeat app can provide reminders to encourage users to be more active.

- Providing a goal-setting feature for the Bellabeat app to encourage its user to reach their objective while using the app.

- To encourage an healthier lifestyle, conduct a test period for community-wide competitions like "Highest Distance Achieved" and provide different incentives like "badge", "community leaderboard", "article shoutout" or potential perks with Bellabeat' partners. This is to check if it will increase the app usage and check the interest of the community and discuss potential partnership with nutrition, activity, sleep, health and beauty, and mindfulness companies.


